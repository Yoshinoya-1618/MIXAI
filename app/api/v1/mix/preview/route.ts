// app/api/v1/mix/preview/route.ts
import { NextRequest } from 'next/server'
import { createClient } from '@supabase/supabase-js'
import { authenticateUser } from '../../../_lib/auth'
import { ApiError, errorResponse } from '../../../_lib/errors'

const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_ROLE_KEY!
)

// POST /v1/mix/preview - ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆï¼ˆ0Cã€30ç§’ï¼‰
export async function POST(request: NextRequest) {
  try {
    const { user } = await authenticateUser(request)
    const userId = user.id
    const { jobId, params, ab = 'USER_EDIT', section } = await request.json()

    if (!jobId) {
      throw new ApiError(400, 'jobId is required')
    }

    console.log(`ğŸ§ Generating preview for job ${jobId}, mode ${ab}`)

    // ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒã‚§ãƒƒã‚¯ï¼ˆåˆ†é–“6ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼‰
    const oneMinuteAgo = new Date(Date.now() - 60000).toISOString()
    const { count } = await supabase
      .from('jobs')
      .select('*', { count: 'exact' })
      .eq('user_id', userId)
      .gte('updated_at', oneMinuteAgo)

    if (count && count >= 6) {
      throw new ApiError(429, 'Rate limit exceeded. Please wait.')
    }

    // ã‚¸ãƒ§ãƒ–ã®å­˜åœ¨ç¢ºèª
    const { data: job } = await supabase
      .from('jobs')
      .select('*')
      .eq('id', jobId)
      .eq('user_id', userId)
      .single()

    if (!job) {
      throw new ApiError(404, 'Job not found or access denied')
    }

    // ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ±ºå®š
    let previewParams = params
    if (!previewParams) {
      previewParams = ab === 'AI_BASE' ? job.ai_params : job.user_params
    }

    if (!previewParams) {
      throw new ApiError(400, 'No parameters available for preview')
    }

    // ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼åŒºé–“ã®æ±ºå®š
    const previewSection = section || {
      start: 15, // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯15ç§’ã‹ã‚‰
      duration: 30 // 30ç§’é–“
    }

    // ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆ
    const previewResult = await generatePreview({
      jobId,
      userId,
      job,
      params: previewParams,
      section: previewSection,
      normalizeToLufs: -14.0 // A/Bæ¯”è¼ƒç”¨ã«æ­£è¦åŒ–
    })

    // æ¸¬å®šçµæœã‚’ä¿å­˜ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    if (ab === 'USER_EDIT' && params) {
      await supabase
        .from('jobs')
        .update({
          user_params: params,
          updated_at: new Date().toISOString()
        })
        .eq('id', jobId)
    }

    console.log(`âœ… Preview generated for job ${jobId}: ${previewResult.previewUrl}`)

    return Response.json({
      success: true,
      previewUrl: previewResult.previewUrl,
      measured: {
        lufs: previewResult.lufs,
        tp: previewResult.truePeak
      },
      chainSummary: previewResult.chainSummary,
      section: previewSection,
      normalizedTo: -14.0,
      meta: {
        job_id: jobId,
        ab_mode: ab,
        processing_time: previewResult.processingTime
      }
    })

  } catch (error) {
    return errorResponse(500, { 
      code: 'preview_generation_error', 
      message: 'ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ', 
      details: error 
    })
  }
}

/**
 * ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆã®å®Ÿè£…
 */
async function generatePreview(options: {
  jobId: string
  userId: string
  job: any
  params: any
  section: { start: number; duration: number }
  normalizeToLufs: number
}) {
  const { execa } = await import('execa')
  const path = await import('path')
  const fs = await import('fs/promises')

  const { jobId, userId, job, params, section, normalizeToLufs } = options
  const startTime = Date.now()

  try {
    // ä¸€æ™‚ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    const tempDir = path.join(process.cwd(), 'temp', jobId)
    await fs.mkdir(tempDir, { recursive: true })

    // Supabase Storageã‹ã‚‰éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    const { data: vocalData } = await supabase.storage
      .from('uta-uploads')
      .download(job.vocal_path)

    const { data: instData } = await supabase.storage
      .from('uta-uploads')
      .download(job.instrumental_path)

    if (!vocalData || !instData) {
      throw new Error('Failed to download audio files')
    }

    const vocalTempPath = path.join(tempDir, 'vocal.wav')
    const instTempPath = path.join(tempDir, 'inst.wav')
    const outputPath = path.join(tempDir, 'preview.wav')

    await fs.writeFile(vocalTempPath, Buffer.from(await vocalData.arrayBuffer()))
    await fs.writeFile(instTempPath, Buffer.from(await instData.arrayBuffer()))

    // FFmpegã§ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆ
    const ffmpegArgs = [
      '-i', vocalTempPath,
      '-i', instTempPath,
      '-filter_complex', buildFilterChain(params, section),
      '-ss', section.start.toString(),
      '-t', section.duration.toString(),
      '-c:a', 'pcm_s16le',
      '-ar', '44100',
      '-y',
      outputPath
    ]

    await execa('ffmpeg', ffmpegArgs, {
      timeout: 60000 // 60ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
    })

    // LUFSæ¸¬å®š
    const lufsResult = await execa('ffmpeg', [
      '-i', outputPath,
      '-af', 'loudnorm=print_format=json',
      '-f', 'null',
      '-'
    ])

    const lufsData = extractLufsData(lufsResult.stderr)

    // ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Storageã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    const previewBuffer = await fs.readFile(outputPath)
    const previewStoragePath = `previews/${userId}/${jobId}/preview_${Date.now()}.wav`

    await supabase.storage
      .from('uta-uploads')
      .upload(previewStoragePath, previewBuffer, {
        contentType: 'audio/wav',
        upsert: true
      })

    // ç½²åURLç”Ÿæˆï¼ˆ5åˆ†é–“æœ‰åŠ¹ï¼‰
    const { data: urlData } = await supabase.storage
      .from('uta-uploads')
      .createSignedUrl(previewStoragePath, 300)

    // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
    await fs.rm(tempDir, { recursive: true, force: true })

    const processingTime = Date.now() - startTime

    return {
      previewUrl: urlData?.signedUrl,
      lufs: lufsData.input_i,
      truePeak: lufsData.input_tp,
      chainSummary: generateChainSummary(params),
      processingTime
    }

  } catch (error) {
    // ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
    const tempDir = path.join(process.cwd(), 'temp', jobId)
    await fs.rm(tempDir, { recursive: true, force: true }).catch(() => {})
    throw error
  }
}

/**
 * ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰FFmpegãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒã‚§ãƒ¼ãƒ³ã‚’æ§‹ç¯‰
 */
function buildFilterChain(params: any, section: { start: number; duration: number }): string {
  const filters: string[] = []

  // ã‚ªãƒ•ã‚»ãƒƒãƒˆè£œæ­£
  if (params.offset_ms) {
    const offsetSec = params.offset_ms / 1000
    filters.push(`[0:a]adelay=${Math.abs(offsetSec * 1000)}|${Math.abs(offsetSec * 1000)}[vocal]`)
  } else {
    filters.push('[0:a]anull[vocal]')
  }

  // ãƒœãƒ¼ã‚«ãƒ«å‡¦ç†ãƒã‚§ãƒ¼ãƒ³
  const vocalProcessing = []
  
  // Air (é«˜åŸŸã‚·ã‚§ãƒ«ãƒ•)
  if (params.air > 0) {
    const airGain = params.air * 2.5 // 0-2.5dB
    vocalProcessing.push(`highshelf=f=8000:g=${airGain}`)
  }

  // Body (ä¸­ä½åŸŸãƒ™ãƒ«)
  if (params.body > 0) {
    const bodyGain = params.body * 2.0 // 0-2.0dB
    vocalProcessing.push(`bell=f=275:g=${bodyGain}:w=0.5`)
  }

  // Vocal (ä¸­åŸŸãƒ™ãƒ«)
  if (params.vocal > 0) {
    const vocalGain = params.vocal * 1.5 // 0-1.5dB
    vocalProcessing.push(`bell=f=3000:g=${vocalGain}:w=0.7`)
  }

  // Clarity (Standard/Creator)
  if (params.clarity > 0) {
    const clarityGain = params.clarity * 2.0 // 0-2.0dB
    vocalProcessing.push(`bell=f=1300:g=${clarityGain}:w=0.4`)
  }

  // ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒã‚§ãƒ¼ãƒ³æ§‹ç¯‰
  if (vocalProcessing.length > 0) {
    filters.push(`[vocal]${vocalProcessing.join(',')}[vocal_processed]`)
  } else {
    filters.push('[vocal]anull[vocal_processed]')
  }

  // ã‚¤ãƒ³ã‚¹ãƒˆå‡¦ç†ï¼ˆåŸå‰‡BYPASSï¼‰
  filters.push('[1:a]anull[inst]')

  // ãƒŸãƒƒã‚¯ã‚¹
  const vocalLevel = 1.0
  const instLevel = params.punch ? (1.0 - params.punch * 0.1) : 1.0 // Punchã§ã‚¤ãƒ³ã‚¹ãƒˆã‚’å°‘ã—ä¸‹ã’ã‚‹

  filters.push(`[vocal_processed][inst]amix=inputs=2:weights=${vocalLevel} ${instLevel}[mixed]`)

  // Width (ã‚¹ãƒ†ãƒ¬ã‚ªå¹…èª¿æ•´)
  if (params.width > 0) {
    const widthFactor = 1.0 + params.width * 0.1 // Â±10%
    filters.push(`[mixed]extrastereo=m=${widthFactor}[stereo]`)
  } else {
    filters.push('[mixed]anull[stereo]')
  }

  // Output Gain
  if (params.output_gain) {
    filters.push(`[stereo]volume=${params.output_gain}dB[output]`)
  } else {
    filters.push('[stereo]anull[output]')
  }

  return filters.join(';')
}

/**
 * FFmpegå‡ºåŠ›ã‹ã‚‰LUFSæ¸¬å®šå€¤ã‚’æŠ½å‡º
 */
function extractLufsData(stderr: string) {
  try {
    const jsonMatch = stderr.match(/\{[\s\S]*\}/)
    if (jsonMatch) {
      return JSON.parse(jsonMatch[0])
    }
  } catch (e) {
    // ãƒ‘ãƒ¼ã‚¹å¤±æ•—æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
  }

  return {
    input_i: -14.0,
    input_tp: -1.0,
    input_lra: 7.0
  }
}

/**
 * å‡¦ç†ãƒã‚§ãƒ¼ãƒ³ã‚µãƒãƒªãƒ¼ç”Ÿæˆ
 */
function generateChainSummary(params: any) {
  const chain = []

  if (params.air > 0) chain.push(`Air: +${(params.air * 2.5).toFixed(1)}dB`)
  if (params.body > 0) chain.push(`Body: +${(params.body * 2.0).toFixed(1)}dB`)
  if (params.vocal > 0) chain.push(`Vocal: +${(params.vocal * 1.5).toFixed(1)}dB`)
  if (params.clarity > 0) chain.push(`Clarity: +${(params.clarity * 2.0).toFixed(1)}dB`)
  if (params.presence > 0) chain.push(`Presence: +${(params.presence * 5.0).toFixed(1)}%`)

  return chain.length > 0 ? chain : ['åŸéŸ³é‡è¦–å‡¦ç†']
}