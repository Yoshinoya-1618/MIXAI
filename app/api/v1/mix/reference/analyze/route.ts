// app/api/v1/mix/reference/analyze/route.ts
import { NextRequest } from 'next/server'
import { createClient } from '@supabase/supabase-js'
import { authenticateUser } from '../../../../_lib/auth'
import { ApiError, errorResponse } from '../../../../_lib/errors'

const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_ROLE_KEY!
)

// POST /v1/mix/reference/analyze - å‚ç…§æ›²è§£æžï¼ˆCreatorã®ã¿ã€0Cï¼‰
export async function POST(request: NextRequest) {
  try {
    const { user } = await authenticateUser(request)
    const userId = user.id
    const { jobId, refUploadId } = await request.json()

    if (!jobId || !refUploadId) {
      throw new ApiError(400, 'jobId and refUploadId are required')
    }

    console.log(`ðŸŽ¯ Starting reference analysis for job ${jobId}`)

    // ãƒ—ãƒ©ãƒ³ç¢ºèªï¼ˆCreatorã®ã¿ï¼‰
    const { data: subscription } = await supabase
      .from('subscriptions')
      .select('plan_code')
      .eq('user_id', userId)
      .eq('status', 'active')
      .single()

    const planCode = subscription?.plan_code
    if (planCode !== 'creator') {
      throw new ApiError(403, 'Reference analysis requires Creator plan')
    }

    // ã‚¸ãƒ§ãƒ–ã®å­˜åœ¨ç¢ºèª
    const { data: job } = await supabase
      .from('jobs')
      .select('*')
      .eq('id', jobId)
      .eq('user_id', userId)
      .single()

    if (!job) {
      throw new ApiError(404, 'Job not found or access denied')
    }

    // æ—¢å­˜ã®å‚ç…§è§£æžã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆå†ªç­‰æ€§ï¼‰
    const { data: existingRef } = await supabase
      .from('mix_refs')
      .select('*')
      .eq('job_id', jobId)
      .eq('upload_id', refUploadId)
      .single()

    if (existingRef) {
      console.log(`âœ… Reference analysis already exists for job ${jobId}`)
      return Response.json({
        success: true,
        cached: true,
        tonalCurve: existingRef.analysis.tonal,
        dynamics: existingRef.analysis.dynamics,
        stereo: existingRef.analysis.stereo,
        weights: existingRef.analysis.weights,
        suggestDiff: existingRef.analysis.suggest_diff,
        meta: {
          job_id: jobId,
          ref_upload_id: refUploadId,
          analysis_cached: true
        }
      })
    }

    // å‚ç…§æ›²è§£æžå®Ÿè¡Œ
    const analysisResult = await performReferenceAnalysis({
      jobId,
      userId,
      job,
      refUploadId
    })

    // å·®åˆ†ææ¡ˆè¨ˆç®—
    const suggestDiff = calculateSuggestedAdjustments(job.user_params || job.ai_params, analysisResult)

    // çµæžœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
    await supabase
      .from('mix_refs')
      .upsert({
        job_id: jobId,
        upload_id: refUploadId,
        analysis: {
          ...analysisResult,
          suggest_diff: suggestDiff,
          analyzed_at: new Date().toISOString()
        }
      })

    console.log(`âœ… Reference analysis completed for job ${jobId}`)

    return Response.json({
      success: true,
      tonalCurve: analysisResult.tonal,
      dynamics: analysisResult.dynamics,
      stereo: analysisResult.stereo,
      weights: analysisResult.weights,
      suggestDiff,
      meta: {
        job_id: jobId,
        ref_upload_id: refUploadId,
        processing_time: analysisResult.processing_time
      }
    })

  } catch (error) {
    return errorResponse(500, { 
      code: 'reference_analysis_error', 
      message: 'å‚ç…§æ›²è§£æžã«å¤±æ•—ã—ã¾ã—ãŸ', 
      details: error 
    })
  }
}

/**
 * å‚ç…§æ›²è§£æžã®å®Ÿè£…
 */
async function performReferenceAnalysis(options: {
  jobId: string
  userId: string
  job: any
  refUploadId: string
}) {
  const { execa } = await import('execa')
  const path = await import('path')
  const fs = await import('fs/promises')

  const { jobId, refUploadId } = options
  const startTime = Date.now()

  try {
    // å‚ç…§æ›²ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    const { data: refData } = await supabase.storage
      .from('uta-uploads')
      .download(`references/${options.userId}/${refUploadId}`)

    if (!refData) {
      throw new Error('Reference file not found')
    }

    // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
    const tempDir = path.join(process.cwd(), 'temp', jobId)
    await fs.mkdir(tempDir, { recursive: true })
    
    const refTempPath = path.join(tempDir, 'reference.wav')
    await fs.writeFile(refTempPath, Buffer.from(await refData.arrayBuffer()))

    // Pythonè§£æžã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
    const pythonScript = path.join(process.cwd(), 'worker', 'reference-analysis.py')
    const result = await execa('python3', [
      pythonScript,
      '--input', refTempPath,
      '--format', 'json'
    ], {
      timeout: 90000 // 90ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
    })

    // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
    await fs.rm(tempDir, { recursive: true, force: true })

    const analysisData = JSON.parse(result.stdout)
    const processingTime = Date.now() - startTime

    return {
      tonal: analysisData.tonal,
      dynamics: analysisData.dynamics,
      stereo: analysisData.stereo,
      weights: {
        tonal: 0.7,
        dynamics: 0.5,
        stereo: 0.3
      },
      processing_time: processingTime
    }

  } catch (error) {
    // ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
    const tempDir = path.join(process.cwd(), 'temp', jobId)
    await fs.rm(tempDir, { recursive: true, force: true }).catch(() => {})
    throw error
  }
}

/**
 * å‚ç…§æ›²ã«åŸºã¥ãèª¿æ•´ææ¡ˆè¨ˆç®—
 */
function calculateSuggestedAdjustments(currentParams: any, refAnalysis: any) {
  const suggestions = {
    air: 0,
    body: 0,
    punch: 0,
    width: 0,
    vocal: 0,
    clarity: 0,
    presence: 0
  }

  // ãƒˆãƒ¼ãƒŠãƒ«ç‰¹æ€§ã«åŸºã¥ãææ¡ˆ
  if (refAnalysis.tonal) {
    // é«˜åŸŸç‰¹æ€§
    if (refAnalysis.tonal.high_shelf > 0.5) {
      suggestions.air = Math.min(1.0, currentParams.air + 0.2)
    } else if (refAnalysis.tonal.high_shelf < -0.5) {
      suggestions.air = Math.max(0.0, currentParams.air - 0.2)
    }

    // ä¸­åŸŸç‰¹æ€§
    if (refAnalysis.tonal.mid_boost > 1.0) {
      suggestions.vocal = Math.min(1.0, currentParams.vocal + 0.15)
      suggestions.clarity = Math.min(1.0, (currentParams.clarity || 0) + 0.1)
    }

    // ä½ŽåŸŸç‰¹æ€§
    if (refAnalysis.tonal.low_shelf > 0.3) {
      suggestions.body = Math.min(1.0, currentParams.body + 0.15)
    }
  }

  // ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ç‰¹æ€§ã«åŸºã¥ãææ¡ˆ
  if (refAnalysis.dynamics) {
    // Crest Factor
    if (refAnalysis.dynamics.crest_factor > 15) {
      suggestions.punch = Math.max(0.0, currentParams.punch - 0.1)
    } else if (refAnalysis.dynamics.crest_factor < 10) {
      suggestions.punch = Math.min(1.0, currentParams.punch + 0.1)
    }
  }

  // ã‚¹ãƒ†ãƒ¬ã‚ªç‰¹æ€§ã«åŸºã¥ãææ¡ˆ
  if (refAnalysis.stereo) {
    if (refAnalysis.stereo.width > 0.9) {
      suggestions.width = Math.min(1.0, currentParams.width + 0.1)
    } else if (refAnalysis.stereo.width < 0.7) {
      suggestions.width = Math.max(0.0, currentParams.width - 0.1)
    }
  }

  return suggestions
}

// GET /v1/mix/reference/analyze - ä¿å­˜æ¸ˆã¿å‚ç…§è§£æžå–å¾—
export async function GET(request: NextRequest) {
  try {
    const { user } = await authenticateUser(request)
    const userId = user.id
    const { searchParams } = new URL(request.url)
    const jobId = searchParams.get('jobId')

    if (!jobId) {
      throw new ApiError(400, 'jobId is required')
    }

    // å‚ç…§è§£æžãƒ‡ãƒ¼ã‚¿å–å¾—
    const { data: refData } = await supabase
      .from('mix_refs')
      .select('*')
      .eq('job_id', jobId)
      .order('created_at', { ascending: false })

    return Response.json({
      success: true,
      references: refData || [],
      count: refData?.length || 0
    })

  } catch (error) {
    return errorResponse(500, { 
      code: 'get_reference_error', 
      message: 'å‚ç…§è§£æžãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ', 
      details: error 
    })
  }
}