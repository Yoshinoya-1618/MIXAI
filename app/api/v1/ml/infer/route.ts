// app/api/v1/ml/infer/route.ts
import { NextRequest } from 'next/server'
import { createServerSupabaseClient } from '../../../../../lib/supabase-server'
import { inferMasteringParams, recommendPreset, calculateAlignmentConfidence } from '../../../../../worker/inference-mock'
import { z } from 'zod'

const inferSchema = z.object({
  jobId: z.string().uuid(),
  task: z.enum(['master_params', 'preset_recommendation', 'alignment_confidence', 'all']),
  audioData: z.object({
    inst: z.string().optional(), // Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
    vocal: z.string().optional()
  }).optional()
})

// POST /v1/ml/infer - AIæ¨è«–ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
export async function POST(request: NextRequest) {
  try {
    const supabase = createServerSupabaseClient(request)
    
    // ãƒ¦ãƒ¼ã‚¶ãƒ¼èªè¨¼ãƒã‚§ãƒƒã‚¯
    const { data: { session }, error: authError } = await supabase.auth.getSession()
    if (authError || !session) {
      return Response.json({ error: 'èªè¨¼ãŒå¿…è¦ã§ã™' }, { status: 401 })
    }

    const body = await request.json()
    const { jobId, task, audioData } = inferSchema.parse(body)

    console.log(`ğŸ¤– Running ML inference for job ${jobId}, task: ${task}`)

    // ã‚¸ãƒ§ãƒ–æƒ…å ±ã®å–å¾—
    let instBuffer: ArrayBuffer | undefined
    let vocalBuffer: ArrayBuffer | undefined

    if (audioData?.inst && audioData?.vocal) {
      // Base64ãƒ‡ã‚³ãƒ¼ãƒ‰
      instBuffer = Buffer.from(audioData.inst, 'base64').buffer
      vocalBuffer = Buffer.from(audioData.vocal, 'base64').buffer
    } else {
      // ã‚¸ãƒ§ãƒ–ã‹ã‚‰éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
      const { data: job, error: jobError } = await supabase
        .from('jobs')
        .select('*')
        .eq('id', jobId)
        .eq('user_id', session.user.id)
        .single()

      if (jobError || !job) {
        return Response.json({ error: 'ã‚¸ãƒ§ãƒ–ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“' }, { status: 404 })
      }

      // Storageã‹ã‚‰éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
      if (job.instrumental_path_trimmed || job.instrumental_path) {
        const instPath = job.instrumental_path_trimmed || job.instrumental_path
        const { data: instData } = await supabase.storage
          .from('audio')
          .download(instPath)
        if (instData) {
          instBuffer = await instData.arrayBuffer()
        }
      }

      if (job.vocal_path) {
        const { data: vocalData } = await supabase.storage
          .from('audio')
          .download(job.vocal_path)
        if (vocalData) {
          vocalBuffer = await vocalData.arrayBuffer()
        }
      }
    }

    if (!instBuffer || !vocalBuffer) {
      return Response.json({ error: 'éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“' }, { status: 400 })
    }

    // æ¨è«–å®Ÿè¡Œ
    const results: any = {}
    
    if (task === 'master_params' || task === 'all') {
      const masterParams = await inferMasteringParams(instBuffer, vocalBuffer, session.user.id)
      if (masterParams) {
        results.masterParams = masterParams
      }
    }

    if (task === 'preset_recommendation' || task === 'all') {
      const presetId = await recommendPreset(instBuffer, vocalBuffer, session.user.id)
      results.recommendedPreset = presetId
    }

    if (task === 'alignment_confidence' || task === 'all') {
      const confidence = await calculateAlignmentConfidence(instBuffer, vocalBuffer, session.user.id)
      results.alignmentConfidence = confidence
    }

    // çµæœã‚’ã‚¸ãƒ§ãƒ–ã«ä¿å­˜ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    if (jobId && Object.keys(results).length > 0) {
      await supabase
        .from('jobs')
        .update({
          ml_inference_results: results,
          ml_inference_at: new Date().toISOString()
        })
        .eq('id', jobId)
    }

    console.log(`âœ… ML inference completed for job ${jobId}`)

    return Response.json({
      success: true,
      jobId,
      results,
      meta: {
        task,
        timestamp: new Date().toISOString()
      }
    })

  } catch (error) {
    console.error('ML inference failed:', error)
    return Response.json({ 
      error: 'MLæ¨è«–ã«å¤±æ•—ã—ã¾ã—ãŸ',
      details: error instanceof Error ? error.message : error
    }, { status: 500 })
  }
}

// GET /v1/ml/infer - æ¨è«–çµæœã®å–å¾—
export async function GET(request: NextRequest) {
  try {
    const supabase = createServerSupabaseClient(request)
    
    const { data: { session }, error: authError } = await supabase.auth.getSession()
    if (authError || !session) {
      return Response.json({ error: 'èªè¨¼ãŒå¿…è¦ã§ã™' }, { status: 401 })
    }

    const { searchParams } = new URL(request.url)
    const jobId = searchParams.get('jobId')

    if (!jobId) {
      return Response.json({ error: 'jobIdãŒå¿…è¦ã§ã™' }, { status: 400 })
    }

    // ã‚¸ãƒ§ãƒ–ã‹ã‚‰æ¨è«–çµæœã‚’å–å¾—
    const { data: job, error } = await supabase
      .from('jobs')
      .select('ml_inference_results, ml_inference_at')
      .eq('id', jobId)
      .eq('user_id', session.user.id)
      .single()

    if (error || !job) {
      return Response.json({ error: 'ã‚¸ãƒ§ãƒ–ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“' }, { status: 404 })
    }

    if (!job.ml_inference_results) {
      return Response.json({ error: 'æ¨è«–çµæœãŒã‚ã‚Šã¾ã›ã‚“' }, { status: 404 })
    }

    return Response.json({
      success: true,
      jobId,
      results: job.ml_inference_results,
      inferredAt: job.ml_inference_at
    })

  } catch (error) {
    return Response.json({ 
      error: 'æ¨è«–çµæœã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ',
      details: error instanceof Error ? error.message : error
    }, { status: 500 })
  }
}